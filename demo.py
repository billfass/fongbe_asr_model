# -*- coding: utf-8 -*-
"""demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12Lr6EKcmOvupn6gXNt1mp3OeiAHHtyCH
"""

#!pip install transformers
#!pip install gradio

import gradio as gr
from transformers import AutoProcessor, AutoModelForCTC
import soundfile as sf
import torch

# Initialize the ASR model
processor = AutoProcessor.from_pretrained("billfass/fongbe_asr_model")
model = AutoModelForCTC.from_pretrained("billfass/fongbe_asr_model")

def asr_audio(file):
    try:
        # Charger le fichier audio
        audio_input, _ = sf.read(file.name)

        # Transcrire l'audio
        inputs = processor(audio_input, return_tensors="pt", padding="longest")
        with torch.no_grad():
            logits = model(input_values=inputs.input_values).logits

        # Convertir les logits en texte
        predicted_ids = torch.argmax(logits, dim=-1)
        transcription = processor.batch_decode(predicted_ids)[0]

        return  transcription
    except Exception as e:
         return {"error": str(e)}

iface = gr.Interface(
    fn=asr_audio,
    inputs="file",
    outputs="text"
)
iface.launch()